# -*- coding: utf-8 -*-
"""m t2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18FPFcYLPmInkhdFe8CE-fRnT1AdqymgF
"""

import networkx as nx
import matplotlib.pyplot as plt
from collections import deque
import random
import numpy as np
from itertools import combinations
import math

# -------------------
# Question 1
# -------------------

# (a) Generate the graph
def generate_graph():
    G = nx.Graph()
    edges = [
        ('A', 'B'), ('A', 'C'), ('A', 'D'), ('B', 'H'), ('C', 'I'),
        ('D', 'E'), ('D', 'F'), ('E', 'G'), ('G', 'H'), ('G', 'J'),
        ('H', 'J'), ('I', 'J'), ('K', 'M'), ('M', 'J'), ('L', 'J')
    ]
    G.add_edges_from(edges)
    return G

# Draw the graph
G = generate_graph()
pos = nx.spring_layout(G)
nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray', font_weight='bold')
plt.title("Undirected Graph")
plt.show()

# (b) BFS Shortest Path
def bfs_shortest_path(graph, start, goal):
    visited = {node: False for node in graph.nodes}
    parent = {node: None for node in graph.nodes}

    queue = deque([start])
    visited[start] = True

    while queue:
        current = queue.popleft()

        for neighbor in graph.neighbors(current):
            if not visited[neighbor]:
                visited[neighbor] = True
                parent[neighbor] = current
                queue.append(neighbor)

                if neighbor == goal:
                    path = []
                    step = goal
                    while step:
                        path.append(step)
                        step = parent[step]
                    return path[::-1]

    return None

shortest_path = bfs_shortest_path(G, 'A', 'K')
print(f"Shortest path from A to K: {shortest_path}")

# (c) Clustering Coefficient
def clustering_coefficient(graph):
    clustering_coeffs = {}
    for node in graph.nodes:
        neighbors = set(graph.neighbors(node))
        k_i = len(neighbors)
        if k_i < 2:
            clustering_coeffs[node] = 0
            continue

        e_i = sum(1 for u, v in combinations(neighbors, 2) if v in graph[u])
        clustering_coeffs[node] = (2 * e_i) / (k_i * (k_i - 1))

    return clustering_coeffs

clustering_coeffs = clustering_coefficient(G)
print("Clustering Coefficients:")
for node, coeff in clustering_coeffs.items():
    print(f"Node {node}: {coeff:.3f}")

# (d) Directed Graph and Adjacency Matrix
DG = G.to_directed()
adj_matrix_undirected = nx.adjacency_matrix(G).todense()
adj_matrix_directed = nx.adjacency_matrix(DG).todense()

print("Adjacency Matrix (Undirected):")
print(adj_matrix_undirected)

print("\nAdjacency Matrix (Directed):")
print(adj_matrix_directed)

# Draw directed graph
pos = nx.spring_layout(DG)
nx.draw(DG, pos, with_labels=True, node_color='lightgreen', edge_color='black', font_weight='bold')
plt.title("Directed Graph")
plt.show()

# -------------------
# Question 2
# -------------------

# Compute effective diameter manually
def compute_effective_diameter(graph):
    largest_cc = max(nx.connected_components(graph), key=len)
    subgraph = graph.subgraph(largest_cc)

    # Get all pairwise shortest path lengths
    sp_lengths = dict(nx.shortest_path_length(subgraph))
    distances = [dist for lengths in sp_lengths.values() for dist in lengths.values() if dist > 0]

    # Sort distances and find the effective diameter (90th percentile)
    distances.sort()
    effective_diameter = distances[int(len(distances) * 0.9) - 1] if distances else 0
    return effective_diameter

def generate_random_graph(n, mean_degree):
    p = mean_degree / (n - 1)
    G = nx.Graph()
    G.add_nodes_from(range(n))

    for i in range(n):
        for j in range(i + 1, n):
            if random.random() < p:
                G.add_edge(i, j)

    return G

def analyze_graph(graph):
    largest_cc = max(nx.connected_components(graph), key=len)
    fraction_in_largest_cc = len(largest_cc) / graph.number_of_nodes()

    # Use custom function to compute effective diameter
    effective_diameter = compute_effective_diameter(graph)

    avg_clustering_coefficient = nx.average_clustering(graph)

    return {
        "nodes": graph.number_of_nodes(),
        "fraction_in_largest_component": fraction_in_largest_cc,
        "effective_diameter": effective_diameter,
        "average_clustering_coefficient": avg_clustering_coefficient
    }

mean_degree = 3
n_values = [100, 1000, 10000, 100000, 1000000]

results = []
for n in n_values:
    G = generate_random_graph(n, mean_degree)
    analysis = analyze_graph(G)
    results.append(analysis)

# Print results
for res in results:
    print(f"#nodes: {res['nodes']}, "
          f"node fraction in largest component: {res['fraction_in_largest_component']:.4f}, "
          f"Effective diameter: {res['effective_diameter']:.4f}, "
          f"Average clustering coefficient: {res['average_clustering_coefficient']:.4f}")

# -------------------
# Question 3
# -------------------

def poisson_distribution(k, c):
    return (math.exp(-c) * (c ** k)) / math.factorial(k)

def plot_degree_distribution(graph, n, p, c=10):
    degree_hist = nx.degree_histogram(graph)
    k_values = range(len(degree_hist))
    probabilities = [degree_hist[k] / graph.number_of_nodes() for k in k_values]
    poisson_probs = [poisson_distribution(k, c) for k in k_values]

    plt.figure(figsize=(10, 6))
    plt.bar(k_values, probabilities, alpha=0.7, label="Degree Distribution")
    plt.plot(k_values, poisson_probs, color='red', label="Poisson Distribution", linewidth=2)
    plt.title(f"Degree Distribution vs Poisson (n={n}, p={p})")
    plt.xlabel("Degree k")
    plt.ylabel("Probability")
    plt.legend()
    plt.savefig(f"degree.randomgraph.meandegree.10.nodes.{n}.png")
    plt.close()

random_graphs = []
n_values = [101, 1001, 10001, 100001, 1000001]
p_values = [0.1, 0.01, 0.001, 0.0001, 0.00001]

for n, p in zip(n_values, p_values):
    G = nx.erdos_renyi_graph(n, p)
    random_graphs.append(G)
    plot_degree_distribution(G, n, p)

# -------------------
# Optional Question 4
# -------------------

# This question requires reading the paper and writing an analysis.
# Since it is optional, you can skip implementing it in code.